{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_excel('./bootcap.xlsx', header=None)\n",
    "test_df = pd.read_excel('./TestData.xlsx', header=None)\n",
    "\n",
    "X_train = train_df.iloc[:, :-1]  # 特征: 前4列\n",
    "y_train = train_df.iloc[:, -1]   # 标签: 最后一列\n",
    "\n",
    "X_test = test_df.iloc[:, :]  # 没有标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你是对的，这个 `HandmadeDecisionTree` 类实现的是一个基本的二叉决策树，它使用基尼不纯度（Gini impurity）来选择最佳分裂特征和阈值，这是 CART 算法的一部分。它也实现了两个基本的停止条件：最大深度和最小样本数。\n",
    "\n",
    "然而，这个类并没有实现信息增益（ID3 算法）和增益率（C4.5 算法）的计算，也没有实现纯度提升的最小阈值这个停止条件。此外，它也没有实现预剪枝和后剪枝。\n",
    "\n",
    "如果你需要这些功能，你可能需要修改 `HandmadeDecisionTree` 类，或者使用一个更完整的决策树实现，比如 scikit-learn 的 `DecisionTreeClassifier`。scikit-learn 的决策树实现了许多高级功能，包括多种分裂质量的度量方法（例如信息增益和基尼不纯度），多种停止条件，以及预剪枝。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HandmadeDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_size=1, min_impurity_decrease=0.0):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.root = None\n",
    "\n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def gini_index(self, groups, classes):\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            for class_val in classes:\n",
    "                p = [row[-1] for row in group].count(class_val) / size\n",
    "                score += p * p\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "\n",
    "    # Split a dataset\n",
    "    def test_split(self, index, value, dataset):\n",
    "        left, right = list(), list()\n",
    "        for row in dataset:\n",
    "            if row[index] < value:\n",
    "                left.append(row)\n",
    "            else:\n",
    "                right.append(row)\n",
    "        return left, right\n",
    "\n",
    "    # Find the best split point given gini index\n",
    "    def get_split(self, dataset):\n",
    "        class_values = list(set(row[-1] for row in dataset))\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        best_gini = 1.0  # initial worst gini\n",
    "        for index in range(len(dataset[0])-1):\n",
    "            for row in dataset:\n",
    "                groups = self.test_split(index, row[index], dataset)\n",
    "                gini = self.gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    current_gini = self.gini_index([dataset], class_values)\n",
    "                    impurity_decrease = current_gini - gini\n",
    "                    if impurity_decrease > self.min_impurity_decrease:  # apply pre-pruning\n",
    "                        b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "                        best_gini = gini\n",
    "        if best_gini == 1.0:  # if best gini no improvement, then no split\n",
    "            return None\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self, group):\n",
    "        outcomes = [row[-1] for row in group]\n",
    "        return max(set(outcomes), key=outcomes.count)\n",
    "\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self, node, max_depth, min_size, depth):\n",
    "        if node is None:  # if node is none then return\n",
    "            return\n",
    "        \n",
    "        left, right = node.get('groups', (None, None))  # get to prevent KeyError\n",
    "        if left is None or right is None:  # if left or right is none then\n",
    "            return\n",
    "        \n",
    "        del(node['groups'])\n",
    "        \n",
    "        # 检查左右子树是否为空\n",
    "        if not left or not right:\n",
    "            node['left'] = node['right'] = self.to_terminal(left + right)\n",
    "            return\n",
    "        \n",
    "        # based on the max_depth and min_size, decide whether to split further\n",
    "        if depth >= max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "        else:\n",
    "            if len(left) <= min_size:\n",
    "                node['left'] = self.to_terminal(left)\n",
    "            else:\n",
    "                node['left'] = self.get_split(left)\n",
    "                self.split(node['left'], max_depth, min_size, depth+1)\n",
    "            \n",
    "            if len(right) <= min_size:\n",
    "                node['right'] = self.to_terminal(right)\n",
    "            else:\n",
    "                node['right'] = self.get_split(right)\n",
    "                self.split(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "    # Build a decision tree\n",
    "    def build_tree(self, train):\n",
    "        self.root = self.get_split(train)\n",
    "        self.split(self.root, self.max_depth, self.min_size, 1)\n",
    " \n",
    "    # Make a prediction with this decision tree\n",
    "    def predict(self, node, row):\n",
    "        if row[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "    # Train\n",
    "    def fit(self, X, y):\n",
    "        dataset = np.column_stack((X,y))\n",
    "        self.build_tree(dataset.tolist())\n",
    "\n",
    "    def predict_row(self, row):\n",
    "        return self.predict(self.root, row)\n",
    "    \n",
    "    # caculate accuracy\n",
    "    def score(self, X, y):\n",
    "        correct = 0\n",
    "        for i in range(len(X)):\n",
    "            if self.predict_row(X.iloc[i, :]) == y.iloc[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1, Size: 1, Impurity Decrease: 0.0, Score: 0.625\n",
      "Depth: 1, Size: 1, Impurity Decrease: 0.001, Score: 0.625\n",
      "Depth: 1, Size: 1, Impurity Decrease: 0.002, Score: 0.625\n",
      "Depth: 1, Size: 1, Impurity Decrease: 0.005, Score: 0.625\n",
      "Depth: 1, Size: 2, Impurity Decrease: 0.0, Score: 0.625\n",
      "Depth: 1, Size: 2, Impurity Decrease: 0.001, Score: 0.625\n",
      "Depth: 1, Size: 2, Impurity Decrease: 0.002, Score: 0.625\n",
      "Depth: 1, Size: 2, Impurity Decrease: 0.005, Score: 0.625\n",
      "Depth: 1, Size: 5, Impurity Decrease: 0.0, Score: 0.625\n",
      "Depth: 1, Size: 5, Impurity Decrease: 0.001, Score: 0.625\n",
      "Depth: 1, Size: 5, Impurity Decrease: 0.002, Score: 0.625\n",
      "Depth: 1, Size: 5, Impurity Decrease: 0.005, Score: 0.625\n",
      "Depth: 1, Size: 10, Impurity Decrease: 0.0, Score: 0.625\n",
      "Depth: 1, Size: 10, Impurity Decrease: 0.001, Score: 0.625\n",
      "Depth: 1, Size: 10, Impurity Decrease: 0.002, Score: 0.625\n",
      "Depth: 1, Size: 10, Impurity Decrease: 0.005, Score: 0.625\n",
      "Depth: 2, Size: 1, Impurity Decrease: 0.0, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 1, Impurity Decrease: 0.001, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 1, Impurity Decrease: 0.002, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 1, Impurity Decrease: 0.005, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 2, Impurity Decrease: 0.0, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 2, Impurity Decrease: 0.001, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 2, Impurity Decrease: 0.002, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 2, Impurity Decrease: 0.005, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 5, Impurity Decrease: 0.0, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 5, Impurity Decrease: 0.001, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 5, Impurity Decrease: 0.002, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 5, Impurity Decrease: 0.005, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 10, Impurity Decrease: 0.0, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 10, Impurity Decrease: 0.001, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 10, Impurity Decrease: 0.002, Score: 0.5666666666666667\n",
      "Depth: 2, Size: 10, Impurity Decrease: 0.005, Score: 0.5666666666666667\n",
      "Depth: 3, Size: 1, Impurity Decrease: 0.0, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 1, Impurity Decrease: 0.001, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 1, Impurity Decrease: 0.002, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 1, Impurity Decrease: 0.005, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 2, Impurity Decrease: 0.0, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 2, Impurity Decrease: 0.001, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 2, Impurity Decrease: 0.002, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 2, Impurity Decrease: 0.005, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 5, Impurity Decrease: 0.0, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 5, Impurity Decrease: 0.001, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 5, Impurity Decrease: 0.002, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 5, Impurity Decrease: 0.005, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 10, Impurity Decrease: 0.0, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 10, Impurity Decrease: 0.001, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 10, Impurity Decrease: 0.002, Score: 0.4666666666666667\n",
      "Depth: 3, Size: 10, Impurity Decrease: 0.005, Score: 0.4666666666666667\n",
      "Depth: 4, Size: 1, Impurity Decrease: 0.0, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 1, Impurity Decrease: 0.001, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 1, Impurity Decrease: 0.002, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 1, Impurity Decrease: 0.005, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 2, Impurity Decrease: 0.0, Score: 0.18333333333333332\n",
      "Depth: 4, Size: 2, Impurity Decrease: 0.001, Score: 0.18333333333333332\n",
      "Depth: 4, Size: 2, Impurity Decrease: 0.002, Score: 0.18333333333333332\n",
      "Depth: 4, Size: 2, Impurity Decrease: 0.005, Score: 0.18333333333333332\n",
      "Depth: 4, Size: 5, Impurity Decrease: 0.0, Score: 0.2\n",
      "Depth: 4, Size: 5, Impurity Decrease: 0.001, Score: 0.2\n",
      "Depth: 4, Size: 5, Impurity Decrease: 0.002, Score: 0.2\n",
      "Depth: 4, Size: 5, Impurity Decrease: 0.005, Score: 0.2\n",
      "Depth: 4, Size: 10, Impurity Decrease: 0.0, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 10, Impurity Decrease: 0.001, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 10, Impurity Decrease: 0.002, Score: 0.19166666666666668\n",
      "Depth: 4, Size: 10, Impurity Decrease: 0.005, Score: 0.19166666666666668\n",
      "Depth: 5, Size: 1, Impurity Decrease: 0.0, Score: 0.06666666666666668\n",
      "Depth: 5, Size: 1, Impurity Decrease: 0.001, Score: 0.06666666666666668\n",
      "Depth: 5, Size: 1, Impurity Decrease: 0.002, Score: 0.06666666666666668\n",
      "Depth: 5, Size: 1, Impurity Decrease: 0.005, Score: 0.06666666666666668\n",
      "Depth: 5, Size: 2, Impurity Decrease: 0.0, Score: 0.075\n",
      "Depth: 5, Size: 2, Impurity Decrease: 0.001, Score: 0.075\n",
      "Depth: 5, Size: 2, Impurity Decrease: 0.002, Score: 0.075\n",
      "Depth: 5, Size: 2, Impurity Decrease: 0.005, Score: 0.075\n",
      "Depth: 5, Size: 5, Impurity Decrease: 0.0, Score: 0.1\n",
      "Depth: 5, Size: 5, Impurity Decrease: 0.001, Score: 0.1\n",
      "Depth: 5, Size: 5, Impurity Decrease: 0.002, Score: 0.1\n",
      "Depth: 5, Size: 5, Impurity Decrease: 0.005, Score: 0.1\n",
      "Depth: 5, Size: 10, Impurity Decrease: 0.0, Score: 0.09166666666666666\n",
      "Depth: 5, Size: 10, Impurity Decrease: 0.001, Score: 0.09166666666666666\n",
      "Depth: 5, Size: 10, Impurity Decrease: 0.002, Score: 0.09166666666666666\n",
      "Depth: 5, Size: 10, Impurity Decrease: 0.005, Score: 0.09166666666666666\n",
      "Best Parameters: {'max_depth': 1, 'min_size': 1, 'min_impurity_decrease': 0.0}, Best Score: 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cross_validate(X, y, n_splits=5, max_depth=None, min_size=1, min_impurity_decrease=0.0, random_state=0): \n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_X, test_X = X.iloc[train_index], X.iloc[test_index]\n",
    "        train_y, test_y = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model = HandmadeDecisionTree(max_depth=max_depth, min_size=min_size, min_impurity_decrease=min_impurity_decrease)\n",
    "        model.fit(train_X, train_y)\n",
    "        scores.append(model.score(test_X, test_y))\n",
    "    return np.mean(scores) \n",
    "\n",
    "max_depths = [1, 2, 3, 4, 5]\n",
    "min_sizes = [1, 2, 5, 10]\n",
    "min_impurity_decreases = [0.0, 0.001, 0.002, 0.005]\n",
    "\n",
    "\n",
    "best_score = 0\n",
    "best_params = {'max_depth': None, 'min_size': 1, 'min_impurity_decrease': 0.0}\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    for min_size in min_sizes:\n",
    "        for min_impurity_decrease in min_impurity_decreases:\n",
    "            avg_score = cross_validate(X_train, y_train, n_splits=5, max_depth=max_depth, min_size=min_size, min_impurity_decrease=min_impurity_decrease)\n",
    "            print(f\"Depth: {max_depth}, Size: {min_size}, Impurity Decrease: {min_impurity_decrease}, Score: {avg_score}\")\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params['max_depth'] = max_depth\n",
    "                best_params['min_size'] = min_size\n",
    "                best_params['min_impurity_decrease'] = min_impurity_decrease\n",
    "\n",
    "print(f\"Best Parameters: {best_params}, Best Score: {best_score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，上面提到的参数搜索和模型评估方法是相对基础的。在实际应用中，可能会使用更复杂的方法（如网格搜索GridSearchCV或随机搜索RandomizedSearchCV），这些方法在机器学习库（如scikit-learn）中已有实现。不过，由于你提到想要从头开始实现决策树，上述方法是一个很好的起点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan nan  3.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2. nan  3. nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    "model = HandmadeDecisionTree(max_depth=4, min_size=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 对测试集进行预测\n",
    "predictions = test_df.apply(model.predict_row, axis=1)\n",
    "\n",
    "predictions = predictions.to_numpy()\n",
    "\n",
    "# 输出预测结果\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=4, min_samples_split=5)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kexueyi/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/utils/_array_api.py:245: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_true contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(predictions, y_pred))\n",
      "File \u001b[0;32m~/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:2545\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2410\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2411\u001b[0m     {\n\u001b[1;32m   2412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2436\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2437\u001b[0m ):\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m \n\u001b[1;32m   2440\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2542\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2545\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2548\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[0;32m~/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/utils/multiclass.py:383\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    381\u001b[0m     data \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39many(data \u001b[38;5;241m!=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(data, \u001b[38;5;28mint\u001b[39m)):\n\u001b[0;32m--> 383\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/utils/validation.py:122\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/gaml/lib/python3.8/site-packages/sklearn/utils/validation.py:171\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(predictions, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(predictions, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
